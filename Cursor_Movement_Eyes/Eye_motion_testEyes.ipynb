{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e97dd499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[91.5121]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# %load testEyes\n",
    "import os\n",
    "import cv2 as cv\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.functional as F\n",
    "\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device  = 'cpu'\n",
    "\n",
    "class eightdeep(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(eightdeep, self).__init__()\n",
    "\n",
    "        f2 = 8\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(1, f2, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(f2),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc1 = nn.Linear(50 * 25 * f2, 200)\n",
    "        self.fc2 = nn.Linear(200, 20)\n",
    "        self.fc3 = nn.Linear(20, 1)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.layer2(x)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class fourdeep(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(fourdeep, self).__init__()\n",
    "\n",
    "        f2 = 4\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(1, f2, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(f2),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc1 = nn.Linear(50 * 25 * f2, 200)\n",
    "        self.fc2 = nn.Linear(200, 20)\n",
    "        self.fc3 = nn.Linear(20, 1)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.layer2(x)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class venty(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(venty, self).__init__()\n",
    "\n",
    "        f2 = 8\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(1, f2, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(f2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc1 = nn.Linear(50 * 25 * f2, 200)\n",
    "        self.fc2 = nn.Linear(200, 10)\n",
    "        self.fc3 = nn.Linear(10, 1)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.layer2(x)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class seven(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(seven, self).__init__()\n",
    "\n",
    "        f2 = 16\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(1, f2, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(f2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc1 = nn.Linear(50 * 25 * f2, 2000)\n",
    "        self.fc2 = nn.Linear(2000, 200)\n",
    "        self.fc3 = nn.Linear(200, 1)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.layer2(x)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class eightfour(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(eightfour, self).__init__()\n",
    "\n",
    "        f1 = 8\n",
    "        f2 = 16\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, f1, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(f1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(f1, f2, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(f2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc1 = nn.Linear(25 * 12 * f2, 400)\n",
    "        self.fc2 = nn.Linear(400, 60)\n",
    "        self.fc3 = nn.Linear(60, 1)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.layer1(x);\n",
    "        x = self.layer2(x);\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.fc1(x);\n",
    "        x = self.fc2(x);\n",
    "        x = self.fc3(x);\n",
    "\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class sixnine(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(sixnine, self).__init__()\n",
    "\n",
    "        f1 = 4\n",
    "        f2 = 16\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, f1, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(f1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(f1, f2, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(f2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc1 = nn.Linear(25 * 12 * f2, 400)\n",
    "        self.fc2 = nn.Linear(400, 60)\n",
    "        self.fc3 = nn.Linear(60, 10)\n",
    "        self.fc4 = nn.Linear(10, 1)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.layer1(x);\n",
    "        x = self.layer2(x);\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.fc1(x);\n",
    "        x = self.fc2(x);\n",
    "        x = self.fc3(x);\n",
    "        x = self.fc4(x);\n",
    "\n",
    "\n",
    "        return x\n",
    "\n",
    "class ConvNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        f1 = 4\n",
    "        f2 = 16\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, f1, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(f1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(f1, f2, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(f2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc1 = nn.Linear(25 * 12 * f2, 400)\n",
    "        self.fc2 = nn.Linear(400, 60)\n",
    "        self.fc3 = nn.Linear(60, 1)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.layer1(x);\n",
    "        x = self.layer2(x);\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.fc1(x);\n",
    "        x = self.fc2(x);\n",
    "        x = self.fc3(x);\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def maxAndMin(featCoords,mult = 1):\n",
    "    adj = 10/mult\n",
    "    listX = []\n",
    "    listY = []\n",
    "    for tup in featCoords:\n",
    "        listX.append(tup[0])\n",
    "        listY.append(tup[1])\n",
    "    maxminList = np.array([min(listX)-adj,min(listY)-adj,max(listX)+adj,max(listY)+adj])\n",
    "    # print(maxminList)\n",
    "    return (maxminList*mult).astype(int), (np.array([sum(listX)/len(listX)-maxminList[0], sum(listY)/len(listY)-maxminList[1]])*mult).astype(int)\n",
    "\n",
    "def getEye(model, times = 1,frameShrink = 0.15, coords = (0,0), counterStart = 0, folder = \"eyes\"):\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    webcam = cv.VideoCapture(0)\n",
    "    counter = counterStart\n",
    "    ims = []\n",
    "\n",
    "    while counter < counterStart+times:\n",
    "        ret, frame = webcam.read()\n",
    "        smallframe = cv.resize(copy.deepcopy(frame), (0, 0), fy=frameShrink, fx=frameShrink)\n",
    "        smallframe = cv.cvtColor(smallframe, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "        feats = face_recognition.face_landmarks(smallframe)\n",
    "        if len(feats) > 0:\n",
    "            leBds, leCenter = maxAndMin(feats[0]['left_eye'], mult=1/frameShrink)\n",
    "\n",
    "            left_eye = frame[leBds[1]:leBds[3], leBds[0]:leBds[2]]\n",
    "            # right_eye = frame[reBds[1]:reBds[3], reBds[0]:reBds[2]]\n",
    "\n",
    "            left_eye = cv.cvtColor(left_eye, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "            left_eye = cv.resize(left_eye, dsize=(100, 50))\n",
    "\n",
    "            # D\n",
    "            # isplay the image - DEBUGGING ONLY\n",
    "            cv.imshow('frame', left_eye)\n",
    "            pred = model(torch.tensor([[left_eye]],dtype=torch.float))\n",
    "            print(1440*pred.item())\n",
    "\n",
    "            if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "def dataLoad(path, want = 0):\n",
    "    nameList = os.listdir(path)\n",
    "\n",
    "    try:\n",
    "        nameList.remove(\".DS_Store\")\n",
    "    except:\n",
    "        pass\n",
    "    totalHolder = []\n",
    "    dims = [1440,900]\n",
    "\n",
    "    for name in nameList:\n",
    "        im = cv.cvtColor(cv.imread(path + \"/\" + name), cv.COLOR_BGR2GRAY)\n",
    "        top = max([max(x) for x in im])\n",
    "        totalHolder.append(((torch.tensor([[im]]).to(dtype=torch.float,device=device))/top,\n",
    "                            torch.tensor([[int((name.split(\".\"))[want])/dims[want]]]).to(dtype=torch.float,device=device)))\n",
    "\n",
    "    # print(totalHolder)\n",
    "    return totalHolder\n",
    "\n",
    "\n",
    "def evaluateModel(model,testSet, sidelen = 1440):\n",
    "    # model.eval()\n",
    "    err = 0\n",
    "    for (im, label) in testSet:\n",
    "        output = model(im)\n",
    "        err += abs(output - label.item())\n",
    "    # model.train()\n",
    "\n",
    "    return (err/len(testSet)*sidelen)\n",
    "\n",
    "\n",
    "# X classifiers\n",
    "\n",
    "# sevsev = seven().to(device)\n",
    "# sevsev.load_state_dict(torch.load(\"xModels/77good.plt\"))\n",
    "# sevsev.eval()\n",
    "#\n",
    "# sevn = ConvNet().to(device)\n",
    "# sevn.load_state_dict(torch.load(\"xModels/79good.plt\"))\n",
    "# sevn.eval()\n",
    "#\n",
    "# eighfour = ConvNet().to(device)\n",
    "# eighfour.load_state_dict(torch.load(\"xModels/84good.plt\"))\n",
    "# eighfour.eval()\n",
    "#\n",
    "# eighnine = ConvNet().to(device)\n",
    "# eighnine.load_state_dict(torch.load(\"xModels/89good.plt\"))\n",
    "# eighnine.eval()\n",
    "#\n",
    "# eighfive = eightfour().to(device)\n",
    "# eighfive.load_state_dict(torch.load(\"xModels/85good.plt\"))\n",
    "# eighfive.eval()\n",
    "#\n",
    "# se = fourdeep().to(device)\n",
    "# se.load_state_dict(torch.load(\"xModels/68.plt\"))\n",
    "# se.eval()\n",
    "#\n",
    "# sn = fourdeep().to(device)\n",
    "# sn.load_state_dict(torch.load(\"xModels/69.plt\"))\n",
    "# sn.eval()\n",
    "\n",
    "sixn = sixnine().to(device)\n",
    "sixn.load_state_dict(torch.load(\"xModels/69good.plt\",map_location=device))\n",
    "sixn.eval()\n",
    "\n",
    "sevent = venty().to(device)\n",
    "sevent.load_state_dict(torch.load(\"xModels/70test.plt\",map_location=device))\n",
    "sevent.eval()\n",
    "\n",
    "\n",
    "# Y classifiers\n",
    "fiv = eightdeep().to(device)\n",
    "fiv.load_state_dict(torch.load(\"yModels/54x1.plt\",map_location=device))\n",
    "fiv.eval()\n",
    "\n",
    "# sone = fourdeep().to(device)\n",
    "# sone.load_state_dict(torch.load(\"yModels/61.plt\"))\n",
    "# sone.eval()\n",
    "#\n",
    "# stwo = fourdeep().to(device)\n",
    "# stwo.load_state_dict(torch.load(\"yModels/62.plt\"))\n",
    "# stwo.eval()\n",
    "\n",
    "testy = dataLoad(\"testeyes\",want=1)\n",
    "testx = dataLoad(\"testeyes\")\n",
    "print(evaluateModel(sixn, testx))\n",
    "\n",
    "trainx = dataLoad(\"eyes\")\n",
    "trainy = dataLoad(\"eyes\",want=1)\n",
    "\n",
    "\n",
    "def ensembleX(im): # 58 accuracy\n",
    "    modList = [sixn,sevent]\n",
    "    sumn = 0\n",
    "    for mod in modList:\n",
    "        sumn += mod(im).item()\n",
    "    return sumn / len(modList)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cca82b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.19044.2006]\n",
      "(c) Microsoft Corporation. All rights reserved.\n",
      "\n",
      "(tensorflow) C:\\Users\\Abdullah\\Desktop\\Webcam-Eyetracking-master>pip install torchvision\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.13.1-cp38-cp38-win_amd64.whl (1.1 MB)\n",
      "Requirement already satisfied: typing-extensions in d:\\anaconda\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from torchvision) (4.1.1)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from torchvision) (1.21.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\anaconda\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from torchvision) (9.0.1)\n",
      "Requirement already satisfied: torch==1.12.1 in d:\\anaconda\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from torchvision) (1.12.1)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from torchvision) (2.27.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from requests->torchvision) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from requests->torchvision) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\anaconda\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.13.1\n",
      "\n",
      "(tensorflow) C:\\Users\\Abdullah\\Desktop\\Webcam-Eyetracking-master>"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c94af3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.19044.2006]\n",
      "(c) Microsoft Corporation. All rights reserved.\n",
      "\n",
      "(tensorflow) C:\\Users\\Abdullah\\Desktop\\Webcam-Eyetracking-master>pip install torch \n",
      "Collecting torch\n",
      "  Downloading torch-1.12.1-cp38-cp38-win_amd64.whl (161.9 MB)\n",
      "Requirement already satisfied: typing-extensions in d:\\anaconda\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from torch) (4.1.1)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.12.1\n",
      "\n",
      "(tensorflow) C:\\Users\\Abdullah\\Desktop\\Webcam-Eyetracking-master>"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "pip install torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9fc4db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd69321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486217dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
